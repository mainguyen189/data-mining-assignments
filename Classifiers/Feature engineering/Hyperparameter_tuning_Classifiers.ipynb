{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7018c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Real\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cfa40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2cb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# The logistic regression model\n",
    "lr = LogisticRegression(solver = 'liblinear', max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dff5a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C is the inverse of regularization strength. Smaller C will result in stronger regularization.\n",
    "search_spaces = {'penalty': Categorical(['l1', 'l2']), 'C': Real(0.01, 100, prior='uniform')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d79c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=17.474316117954075, max_iter=1000, penalty='l1',\n",
      "                   solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Create a BayesSearchCV model\n",
    "clf = BayesSearchCV(lr, search_spaces=search_spaces, n_iter=10)\n",
    "\n",
    "# Fit the BayesSearchCV model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Show which hyperparameters performed the best\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebb3389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('C', 32.37502499624655), ('penalty', 'l2')]), OrderedDict([('C', 17.474316117954075), ('penalty', 'l1')]), OrderedDict([('C', 1.87711566720154), ('penalty', 'l1')]), OrderedDict([('C', 49.99715956440307), ('penalty', 'l2')]), OrderedDict([('C', 11.542539977726387), ('penalty', 'l1')]), OrderedDict([('C', 90.40228761439442), ('penalty', 'l2')]), OrderedDict([('C', 86.48038599998013), ('penalty', 'l1')]), OrderedDict([('C', 99.17712875297852), ('penalty', 'l1')]), OrderedDict([('C', 64.05624598587704), ('penalty', 'l1')]), OrderedDict([('C', 99.10884148406537), ('penalty', 'l2')])]\n",
      "[0.96949384 0.97181943 0.95543092 0.96949384 0.97181943 0.97181943\n",
      " 0.96711354 0.96711354 0.9647606  0.97181943]\n"
     ]
    }
   ],
   "source": [
    "# Print the the parameters and mean test score\n",
    "print(clf.cv_results_['params'])\n",
    "print(clf.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711d0b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C penalty  Accuracy\n",
      "1  17.474316      l1  0.971819\n",
      "4  11.542540      l1  0.971819\n",
      "5  90.402288      l2  0.971819\n",
      "9  99.108841      l2  0.971819\n",
      "0  32.375025      l2  0.969494\n",
      "3  49.997160      l2  0.969494\n",
      "6  86.480386      l1  0.967114\n",
      "7  99.177129      l1  0.967114\n",
      "8  64.056246      l1  0.964761\n",
      "2   1.877116      l1  0.955431\n"
     ]
    }
   ],
   "source": [
    "# Create and print Pandas DataFrame\n",
    "cv_table = pd.concat([pd.DataFrame(clf.cv_results_['params']), pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['Accuracy'])], axis=1)\n",
    " \n",
    "print(cv_table.sort_values('Accuracy', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dafd444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "# Assess the model's accuracy on the testing data\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c9fbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SVC model\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d4e585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Dictionary of parameters for GridSearchCV\n",
    "parameters = {'kernel': ['linear', 'rbf', 'sigmoid'], 'C': [1, 10, 100]}\n",
    "\n",
    "# Create a GridSearchCV model\n",
    "grid = GridSearchCV(svm, parameters)\n",
    "\n",
    "# Fit the GridSearchCV model to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the model and hyperparameters obtained by GridSearchCV\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e807a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Score                    \n",
      "C             1         10        100\n",
      "kernel                               \n",
      "linear   0.969494  0.967168  0.962462\n",
      "rbf      0.927360  0.929658  0.946129\n",
      "sigmoid  0.513844  0.422134  0.419808\n"
     ]
    }
   ],
   "source": [
    "# Print a table summarizing the results of GridSearchCV\n",
    "df = pd.concat([pd.DataFrame(grid.cv_results_['params']), pd.DataFrame(grid.cv_results_['mean_test_score'], columns=['Score'])], axis=1)\n",
    "cv_table = df.pivot(index='kernel', columns='C')\n",
    "print(cv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05bf6196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the final model on the test data\n",
    "print(grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3d4d27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=12.441136032413821, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of parameters for BayesSearchCV\n",
    "search_spaces = {'kernel': Categorical(['linear', 'rbf', 'sigmoid']), 'C': Real(1, 100, prior='uniform')}\n",
    "\n",
    "# Create a BayesSearchCV model\n",
    "bayes = BayesSearchCV(svm, search_spaces, n_iter=10)\n",
    "\n",
    "# Fit the BayesSearchCV model to the training data\n",
    "bayes.fit(X_train, y_train)\n",
    "\n",
    "# Print the model and hyperparameters obtained by BayesSearchCV\n",
    "print(bayes.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7398412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916083916083916\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the final model on the test data\n",
    "print(bayes.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ddad806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TPOTClassifier model\n",
    "tpot = TPOTClassifier(generations=2, population_size=5, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff264186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \n",
      "Generation 1 - Current best internal CV score: 0.97890560875513\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: 0.97890560875513\n",
      "                                                                            \n",
      "Best pipeline: LinearSVC(input_matrix, C=15.0, dual=False, loss=squared_hinge, penalty=l1, tol=0.001)\n",
      "0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "#fit and print accuracy\n",
    "tpot.fit(X_train,y_train)\n",
    "print(tpot.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13febb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
