{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064ae753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3de149",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('bone-marrow.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "df.drop(columns=['Disease'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48eb8a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all columns to numeric, coerce errors to null values\n",
    "for c in df.columns:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    \n",
    "#Make sure binary columns are encoded as 0 and 1\n",
    "for c in df.columns[df.nunique()==2]:\n",
    "    df[c] = (df[c]==1)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d59eb074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique values in each column:\n",
      "Recipientgender           2\n",
      "Stemcellsource            2\n",
      "Donorage                187\n",
      "Donorage35                2\n",
      "IIIV                      2\n",
      "Gendermatch               2\n",
      "DonorABO                  4\n",
      "RecipientABO              4\n",
      "RecipientRh               2\n",
      "ABOmatch                  2\n",
      "CMVstatus                 4\n",
      "DonorCMV                  2\n",
      "RecipientCMV              2\n",
      "Riskgroup                 2\n",
      "Txpostrelapse             2\n",
      "Diseasegroup              2\n",
      "HLAmatch                  4\n",
      "HLAmismatch               2\n",
      "Antigen                   4\n",
      "Alel                      5\n",
      "HLAgrI                    7\n",
      "Recipientage            125\n",
      "Recipientage10            2\n",
      "Recipientageint           3\n",
      "Relapse                   2\n",
      "aGvHDIIIIV                2\n",
      "extcGvHD                  2\n",
      "CD34kgx10d6             183\n",
      "CD3dCD34                182\n",
      "CD3dkgx10d8             163\n",
      "Rbodymass               130\n",
      "ANCrecovery              18\n",
      "PLTrecovery              50\n",
      "time_to_aGvHD_III_IV     28\n",
      "survival_time           174\n",
      "survival_status           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Calculate the number of unique values for each column\n",
    "print('Count of unique values in each column:')\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9413ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set target, survival_status,as y; features (dropping survival status and time) as X\n",
    "y = df.survival_status\n",
    "X= df.drop(columns=['survival_time','survival_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1fe354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Index(['RecipientABO', 'CMVstatus', 'Antigen', 'Alel', 'CD3dCD34',\n",
      "       'CD3dkgx10d8', 'Rbodymass'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Define lists of numeric and categorical columns based on number of unique values\n",
    "num_cols = X.columns[X.nunique()>7]\n",
    "cat_cols = X.columns[X.nunique()<=7]\n",
    "\n",
    "#Print columns with missing values\n",
    "print('Columns with missing values:')\n",
    "print(X.columns[X.isnull().sum()>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88089deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde54b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create categorical preprocessing pipeline\n",
    "#Using mode to fill in missing values and OHE\n",
    "cat_vals = Pipeline([(\"imputer\",SimpleImputer(strategy='most_frequent')), (\"ohe\",OneHotEncoder(sparse=False, drop='first', handle_unknown = 'ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865a9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create numerical preprocessing pipeline\n",
    "# Using mean to fill in missing values and standard scaling of features\n",
    "num_vals = Pipeline([(\"imputer\",SimpleImputer(strategy='mean')), (\"scale\",StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a7a5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column transformer that will preprocess the numerical and categorical features separately\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat_process\", cat_vals, cat_cols),\n",
    "        (\"num_process\", num_vals, num_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa01cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline with preprocess, PCA, and a logistic regresssion model\n",
    "pipeline = Pipeline([(\"preprocess\",preprocess), \n",
    "                     (\"pca\", PCA()),\n",
    "                     (\"clf\",LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e3f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Accuracy Test Set:\n",
      "0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "#Fit the pipeline on the training data\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "#Predict the pipeline on the test data\n",
    "print('Pipeline Accuracy Test Set:')\n",
    "print(pipeline.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0850cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define search space of hyperparameters\n",
    "search_space = [{'clf':[LogisticRegression()],\n",
    "                     'clf__C': np.logspace(-4, 2, 10),\n",
    "                'pca__n_components':np.linspace(5,35,7).astype(int)},\n",
    "                {'clf': [RandomForestClassifier()], # Actual Estimator\n",
    "                'clf__max_depth': np.linspace(2,20,10).astype(int),\n",
    "                'pca__n_components':np.linspace(5,35,7).astype(int)}\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d92755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search over hyperparameters abolve to optimize pipeline and fit\n",
    "gs = GridSearchCV(pipeline, search_space, cv=5)\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "#Save the best estimator from the gridsearch and print attributes and final accuracy on test set\n",
    "best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d5d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print attributes of best_model\n",
    "print('The best classification model is:')\n",
    "print(best_model.named_steps['clf'])\n",
    "print('The hyperparameters of the best classification model are:')\n",
    "print(best_model.named_steps['clf'].get_params())\n",
    "print('The number of components selected in the PCA step are:')\n",
    "print(best_model.named_steps['pca'].n_components)\n",
    "\n",
    "#Print final accuracy score \n",
    "print('Best Model Accuracy Test Set:')\n",
    "print(best_model.score(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
